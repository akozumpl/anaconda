#!/usr/bin/python
#
# makeupdates - Generate an updates.img containing changes since the last
#               tag, but only changes to the main anaconda runtime.
#               initrd/stage1 updates have to be created separately.
#
# Copyright (C) 2009  Red Hat, Inc.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as published
# by the Free Software Foundation; either version 2.1 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# Author: David Cantrell <dcantrell@redhat.com>

import getopt
import os
import shutil
import subprocess
import sys
import re
import glob
import urllib
import threading
import multiprocessing

RPM_FOLDER_NAME = os.path.expanduser("~/.anaconda_updates_rpm_cache")
KOJI_BASE_URL = "http://kojipkgs.fedoraproject.org//packages/" \
                "%(toplevel_name)s/%(toplevel_version)s/%(release)s/%(arch)s/%(rpm_name)s"


def getArchiveTag(configure, spec):
    tag = ""

    with open(configure, "r") as f:
        for line in f:
            if line.startswith('AC_INIT('):
                fields = line.split('[')
                tag += fields[1].split(']')[0] + '-' + fields[2].split(']')[0]
                break
            else:
                continue

    with open(spec, "r") as f:
        for line in f:
            if line.startswith('Release:'):
                tag += '-' + line.split()[1].split('%')[0]
            else:
                continue

    return tag

def getArchiveTagOffset(configure, spec, offset):
    tag = getArchiveTag(configure, spec)

    if not tag.count("-") >= 2:
        return tag
    ldash = tag.rfind("-")
    bldash = tag[:ldash].rfind("-")
    ver = tag[bldash+1:ldash]

    if not ver.count(".") >= 1:
        return tag
    ver = ver[:ver.rfind(".")]

    if not len(ver) > 0:
        return tag
    globstr = "refs/tags/" + tag[:bldash+1] + ver + ".*"
    proc = subprocess.Popen(['git', 'for-each-ref', '--sort=taggerdate',
                             '--format=%(tag)', globstr],
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE).communicate()
    lines = proc[0].strip("\n").split('\n')
    lines.reverse()

    try:
        return lines[offset]
    except IndexError:
        return tag

def get_anaconda_version():
    """Get current anaconda version as string from the configure script"""
    with open("configure.ac", "rc") as f:
        match = re.search(r"AC_INIT\(\[.*\],\ \[(.*)\],\ \[.*\]\)", f.read())
    return match.groups()[0]

def get_fedora_version():
    """Return integer representing current Fedora number,
    based on Anaconda version"""
    anaconda_version = get_anaconda_version()
    return int(anaconda_version.split(".")[0])

def doGitDiff(tag, args=[]):
    proc = subprocess.Popen(['git', 'diff', '--name-status', tag] + args,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE).communicate()

    lines = proc[0].split('\n')
    return lines

def doGitContentDiff(tag, args=[]):
    proc = subprocess.Popen(['git', 'diff', tag] + args,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE).communicate()
    lines = proc[0].split('\n')
    return lines

def download_to_file(url, path):
    """Download a file to the given path,
    return the storage path if successful,
    or None if the download fails for some reason
    """
    try:
        result = urllib.urlretrieve(url, path)
        # return the storage path
        return result[0]
    except Exception, e:
        print("download of %s to %s failed with exception: %s" % (url, path, e))
        return None

def create_RPM_cache_folder():
    """Create RPM package cache folder if it does not already exist"""
    if not os.path.exists(RPM_FOLDER_NAME):
        os.makedirs(RPM_FOLDER_NAME)

def copyUpdatedFiles(tag, updates, cwd):
    def pruneFile(src, names):
        lst = []

        for name in names:
            if name.startswith('Makefile') or name.endswith('.pyc'):
                lst.append(name)

        return lst

    def install_to_dir(fname, relpath):
        sys.stdout.write("Including %s\n" % fname)
        outdir = os.path.join(updates, relpath)
        if not os.path.isdir(outdir):
            os.makedirs(outdir)
        shutil.copy2(file, outdir)

    subdirs = []

    # Updates get overlaid onto the runtime filesystem. Anaconda expects them
    # to be in /run/install/updates, so put them in
    # $updatedir/run/install/updates.
    tmpupdates = updates.rstrip('/')
    if not tmpupdates.endswith("/run/install/updates"):
        tmpupdates = os.path.join(tmpupdates, "run/install/updates")

    lines = doGitDiff(tag)
    for line in lines:
        fields = line.split()

        if len(fields) < 2:
            continue

        status = fields[0]
        file = fields[1]

        if status == "D":
            continue

        if file.endswith('.spec.in') or (file.find('Makefile') != -1) or \
           file.endswith('.c') or file.endswith('.h') or \
           file.endswith('.sh') or file == 'configure.ac':
            continue

        if file.endswith('.glade'):
            # Some UI files should go under ui/<dir> where dir is the
            # directory above the file.glade
            dir_parts = os.path.dirname(file).split(os.path.sep)
            g_idx = dir_parts.index("gui")
            uidir = os.path.sep.join(dir_parts[g_idx+1:])
            path_comps = [tmpupdates, "ui"]
            if uidir:
                path_comps.append(uidir)
            install_to_dir(file, os.path.join(*path_comps))
        elif file.startswith('pyanaconda/'):
            # pyanaconda stuff goes into /tmp/updates/[path]
            dirname = os.path.join(tmpupdates, os.path.dirname(file))
            install_to_dir(file, dirname)
        elif file == 'anaconda':
            # anaconda itself we just overwrite
            install_to_dir(file, "usr/sbin")
        elif file.endswith('.service') or file.endswith(".target"):
            # same for systemd services
            install_to_dir(file, "lib/systemd/system")
        elif file.endswith('/anaconda-generator'):
            # yeah, this should probably be more clever..
            install_to_dir(file, "lib/systemd/system-generators")
        elif file == "data/tmux.conf":
            install_to_dir(file, "usr/share/anaconda")
        elif file == "data/interactive-defaults.ks":
            install_to_dir(file, "usr/share/anaconda")
        elif file == "data/liveinst/liveinst":
            install_to_dir(file, "usr/sbin")
        elif file.startswith("data/pixmaps"):
            install_to_dir(file, "usr/share/anaconda/pixmaps")
        elif file.startswith("data/ui/"):
            install_to_dir(file, "usr/share/anaconda/ui")
        elif file.startswith("data/post-scripts/"):
            install_to_dir(file, "usr/share/anaconda/post-scripts")
        elif file.endswith("anaconda-yum"):
            install_to_dir(file, "usr/libexec/anaconda")
        elif file.find('/') != -1:
            fields = file.split('/')
            subdir = fields[0]
            if subdir in ['po', 'scripts','command-stubs', 'tests',
                          'docs', 'fonts', 'utils',
                          'liveinst', 'dracut', 'data']:
                continue
            else:
                sys.stdout.write("Including %s\n" % (file,))
                install_to_dir(file, tmpupdates)
        else:
            sys.stdout.write("Including %s\n" % (file,))
            install_to_dir(file, tmpupdates)

def _compilableChanged(tag, compilable):
    lines = doGitDiff(tag, [compilable])

    for line in lines:
        fields = line.split()

        if len(fields) < 2:
            continue

        status = fields[0]
        file = fields[1]

        if status == "D":
            continue

        if file.startswith('Makefile') or file.endswith('.h') or \
           file.endswith('.c') or file.endswith('.py'):
            return True

    return False

def isysChanged(tag):
    return _compilableChanged(tag, 'pyanaconda/isys')

def widgetsChanged(tag):
    return _compilableChanged(tag, 'widgets')

def copyUpdatedIsys(updates, cwd):
    os.chdir(cwd)

    if not os.path.isfile('Makefile'):
        if not os.path.isfile('configure'):
            os.system('./autogen.sh')
        os.system('./configure --prefix=`rpm --eval %_prefix`')

    os.system('make -j %d' % multiprocessing.cpu_count())

    # Updates get overlaid onto the runtime filesystem. Anaconda expects them
    # to be in /run/install/updates, so put them in
    # $updatedir/run/install/updates.
    tmpupdates = updates.rstrip('/')
    if not tmpupdates.endswith("/run/install/updates/pyanaconda"):
        tmpupdates = os.path.join(tmpupdates, "run/install/updates/pyanaconda")

    if not os.path.isdir(tmpupdates):
        os.makedirs(tmpupdates)

    isysmodule = os.path.realpath(cwd + '/pyanaconda/isys/.libs/_isys.so')

    if os.path.isfile(isysmodule):
        shutil.copy2(isysmodule, tmpupdates)

def copyUpdatedWidgets(updates, cwd):
    os.chdir(cwd)

    if os.path.isdir("/lib64"):
        libdir = "/lib64/"
    else:
        libdir = "/lib/"

    if not os.path.isdir(updates + libdir):
        os.makedirs(updates + libdir)

    if not os.path.isdir(updates + libdir + "girepository-1.0"):
        os.makedirs(updates + libdir + "girepository-1.0")

    if not os.path.isfile('Makefile'):
        if not os.path.isfile('configure'):
            os.system('./autogen.sh')
        os.system('./configure --prefix=`rpm --eval %_prefix` --enable-gtk-doc --enable-introspection')

    os.system('make')

    files = ["libAnacondaWidgets.so", "libAnacondaWidgets.so.0", "libAnacondaWidgets.so.0.0.0"]
    for f in files:
        path = os.path.normpath(cwd + "/widgets/src/.libs/" + f)
        if os.path.islink(path) and not os.path.exists(updates + libdir + os.path.basename(path)):
            os.symlink(os.readlink(path), updates + libdir + os.path.basename(path))
        elif os.path.isfile(path):
            shutil.copy2(path, updates + libdir)

    typelib = os.path.realpath(cwd + "/widgets/src/AnacondaWidgets-1.0.typelib")
    if os.path.isfile(typelib):
        shutil.copy2(typelib, updates + libdir + "girepository-1.0")

def addRpms(updates, add_rpms):
    for rpm in add_rpms:
        cmd = "cd %s && rpm2cpio %s | cpio -dium" % (updates, rpm)
        sys.stdout.write(cmd+"\n")
        os.system(cmd)

def createUpdatesImage(cwd, updates):
    os.chdir(updates)
    os.system("find . | cpio -c -o | gzip -9cv > %s/updates.img" % (cwd,))
    sys.stdout.write("updates.img ready\n")

def check_for_new_packages(tag, arch):
    """Download any new packages added to Requires and Defines
    since the given tag, return list of RPM paths
    """
    new_packages = {}
    second_pass = []
    diff = doGitContentDiff(tag, ["anaconda.spec.in"])
    new_requires = filter(lambda x: x.startswith("+Requires:"), diff)
    new_defines = filter(lambda x: x.startswith("+%define"), diff)

    # parse all new requires and defines for package name and version

    # parse requires

    for req in new_requires:
        parts = req.split()
        if len(parts) < 2:
            # must contain at least "+Requires:" and "some_package"
            continue
        package = parts[1]
        if len(parts) > 2:
            version = parts.pop()
        else:
            version = ""

        # handle version variables (%{package-namever})
        if version.startswith("%"):
            # drop the %{ prefix and ver} suffix
            version_var = version[2:-4]
            second_pass.append((package, version_var))
        else:
            new_packages[package] = version

    for define in new_defines:
        # second word & split the "ver" suffix
        package = define.split()[1][:-3]
        version = define.split()[2]
        new_packages[package] = version

    # resolve version variables against already added packages
    # TODO: handle links to packages that were not added in the diff
    for package, versions_var in second_pass:
        version = new_packages.get(versions_var, None)
        if version:
            new_packages[package] = version

    # parse defines
    if new_packages:
        print("found %d new packages in Defines and Requires" %
              len(new_packages))
    else:
        print("no new Defines or Requires found")
        return []

    # make sure the RPM cache folder exists
    create_RPM_cache_folder()
    fedora_number = get_fedora_version()
    # remove available packages from the list
    new_packages, include_rpms = remove_local_packages(new_packages, arch)
    # if some packages are not locally available, download them from Koji
    if new_packages:
        include_rpms.extend(get_RPMs_from_koji(new_packages, fedora_number, arch))
    # return absolute paths for the packages
    return map(lambda x: os.path.abspath(x), include_rpms)

def remove_local_packages(packages, arch):
    """Remove locally available RPMs from the list of needed packages,
    return locally unavailable packages and paths to relevant locally
    available RPMs for inclusion"""
    # list all package names and version for the RPMs already in cache
    folder_glob = os.path.join(RPM_FOLDER_NAME, "*.rpm")
    folder_glob = os.path.abspath(folder_glob)
    include_rpms = []
    # only check RPMs that are either noarch or built for the
    # currently specified architecture
    allowed = ("noarch.rpm", "%s.rpm" % arch)
    relevant_rpms = [x for x in glob.glob(folder_glob) if x.endswith(allowed)]

    # iterate over all relevant cached RPMs and check if they are needed
    for rpm_path in relevant_rpms:
        proc = subprocess.Popen(['rpm', '-qp', '--queryformat',
                                '%{NAME} %{VERSION} %{RELEASE}', rpm_path],
                                stdout=subprocess.PIPE,
                                stderr=None)
        proc_output = proc.communicate()
        if proc.returncode != 0:
            continue
        name, version, release = proc_output[0].split()
        # add the build number, extracted from release
        version_build = "%s-%s" % (version, release.split(".")[0])
        # check if the package is needed
        if name in packages:
            requested_version = packages[name]
            # handle versions with build number and without it
            if not requested_version or requested_version == version_build or \
                    requested_version == version:
                include_rpms.append(rpm_path)
                del packages[name]

    # return only those packages that are not locally available
    if include_rpms and not packages:
        print("all %d RPMs found locally:" % len(include_rpms))
    elif include_rpms:
        print("%d RPMs found locally:" % len(include_rpms))
    else:
        print("no packages found locally")
    for rpm in include_rpms:
        print(os.path.basename(rpm))
    return packages, include_rpms

def get_RPMs_from_koji(packages, fedora_number, arch):
    """Get RPM download URLs for given packages and Fedora version,
    return URLS and RPM filenames
    """
    threads = []
    rpm_paths = []
    # the print lock is used to make sure only one
    # thread is printing to stdout at a time
    print_lock = threading.Lock()

    index = 1
    print("starting %d worker threads" % len(packages))
    for package, version in packages.iteritems():
        package_version = (package, version)
        thread = threading.Thread(name=index, target=get_rpm_from_Koji_thread,
                                  args=(package_version, fedora_number,
                                        arch, rpm_paths, print_lock))
        thread.start()
        threads.append(thread)
        index+=1
    # wait for all threads to finish
    for thread in threads:
        thread.join()

    print("%d RPMs have been downloaded" % len(rpm_paths))

    # return the list of paths for the downloaded RPMs
    return rpm_paths

def get_rpm_from_Koji_thread(package, fedora_number, arch,
                             rpm_paths, print_lock):
    """Download the given package from Koji and if successful,
    append the path to the downloaded file to the rpm_paths list
    """
    # just to be sure, create a separate session for each query,
    # as the individual lookups will run in different threads
    import koji
    kojiclient = koji.ClientSession('http://koji.fedoraproject.org/kojihub', {})
    name, version = package
    if not version:
        version = "*"
    # check if version contains build number or not
    if len(version.split("-")) == 1:
        version = "%s-*" % version
    package_glob = "%s-%s.fc%d.*.rpm" % (name, version, fedora_number)

    # get the current thread, so output can be prefixed by thread number
    prefix = "thread %s:" % threading.current_thread().name
    with print_lock:
        print("%s searching for: %s in Koji" % (prefix, package_glob))
    # call the Koji API
    results = kojiclient.search(package_glob, "rpm", "glob")
    # leave only results that are either noarch
    # or are built for the current architecture
    allowed = ("noarch.rpm", "%s.rpm" % arch)
    results = [x for x in results if x['name'].endswith(allowed)]
    if results:  # any packages left ?
        package_metadata = {}
        rpm_name = results[0]['name']
        package_metadata['rpm_name'] = rpm_name
        with print_lock:
            print("%s RPM found: %s" % (prefix, rpm_name))
        rpm_id = results[0]['id']

        # get info about the RPM to
        # get the arch and build_id
        result = kojiclient.getRPM(rpm_id)
        package_metadata['arch'] = result['arch']
        package_metadata['release'] = result['release']
        build_id = result['build_id']

        # so we can get the toplevel package name and version
        result = kojiclient.getBuild(build_id)
        package_metadata['toplevel_name'] = result['package_name']
        package_metadata['toplevel_version'] = result['version']

        # and use the information to build the URL
        url = KOJI_BASE_URL % package_metadata
        # simple, isn't it ? :)

        # append the RPM cache folder to the filename
        download_path = os.path.join(RPM_FOLDER_NAME, rpm_name)
        # check if the download was successful
        storage_path = download_to_file(url, download_path)
        if storage_path is not None:
            with print_lock:
                print("%s download done: %s" % (prefix, rpm_name))
            # add successful downloads to the RPM inclusion list
            rpm_paths.append(storage_path)
            # GIL should be enough for appending to the list
            # from multiple threads
        else:
            with print_lock:
                print("%s download failed: %s @ %s" % (prefix, rpm_name, url))
    else:
        with print_lock:
            print("%s warning: %s not found in Koji" % (prefix, package_glob))

def usage(cmd):
    sys.stdout.write("Usage: %s [OPTION]...\n" % (cmd,))
    sys.stdout.write("Options:\n")
    sys.stdout.write("    -k, --keep       Do not delete updates subdirectory.\n")
    sys.stdout.write("    -c, --compile    Compile code if there are isys changes.\n")
    sys.stdout.write("    -h, --help       Display this help and exit.\n")
    sys.stdout.write("    -t, --tag        Make image from TAG to HEAD.\n")
    sys.stdout.write("    -o, --offset     Make image from (latest_tag - OFFSET) to HEAD.\n")
    sys.stdout.write("    -a, --add        Add contents of rpm to the update\n")
    sys.stdout.write("    -f, --fetch      Autofetch new dependencies from Koji for ARCH\n")
    sys.stdout.write("                     (cached in ~/.anaconda_updates_rpm_cache)\n")

def main(argv):
    prog = os.path.basename(sys.argv[0])
    cwd = os.getcwd()
    configure = os.path.realpath(cwd + '/configure.ac')
    spec = os.path.realpath(cwd + '/anaconda.spec.in')
    updates = cwd + '/updates'
    keep, compile, help, unknown = False, False, False, False
    tag = None
    opts = []
    offset = 0
    add_rpms = []
    fetch = False
    arch = None

    try:
        opts, args = getopt.getopt(sys.argv[1:], 'a:t:f:o:kc?',
                                   ['add=', 'tag=', 'offset=',
                                    'keep', 'compile', 'help', 'fetch='])
    except getopt.GetoptError:
        help = True

    for o, a in opts:
        if o in ('-k', '--keep'):
            keep = True
        elif o in ('-c', '--compile'):
            compile = True
        elif o in ('-?', '--help'):
            help = True
        elif o in ('-t', '--tag'):
            tag = a
        elif o in ('-o', '--offset'):
            offset = int(a)
        elif o in ('-a', '--add'):
            add_rpms.append(os.path.abspath(a))
        elif o in ('-f', '--fetch'):
            fetch = True
            if a == "":
                help = True
            else:
                arch = a
        else:
            unknown = True

    if help:
        usage(prog)
        sys.exit(0)
    elif unknown:
        sys.stderr.write("%s: extra operand `%s'" % (prog, sys.argv[1],))
        sys.stderr.write("Try `%s --help' for more information." % (prog,))
        sys.exit(1)

    if not os.path.isfile(configure) and not os.path.isfile(spec):
        sys.stderr.write("You must be at the top level of the anaconda source tree.\n")
        sys.exit(1)

    if not tag:
        if offset < 1:
            tag = getArchiveTag(configure, spec)
        else:
            tag = getArchiveTagOffset(configure, spec, offset)
        sys.stdout.write("Using tag: %s\n" % tag)

    if not os.path.isdir(updates):
        os.makedirs(updates)

    copyUpdatedFiles(tag, updates, cwd)

    if compile:
        if isysChanged(tag):
            copyUpdatedIsys(updates, cwd)

        if widgetsChanged(tag):
            copyUpdatedWidgets(updates, cwd)

    if fetch:
        rpm_paths = check_for_new_packages(tag, arch)
        add_rpms.extend(rpm_paths)

    if add_rpms:
        addRpms(updates, add_rpms)

    createUpdatesImage(cwd, updates)

    if not keep:
        shutil.rmtree(updates)

if __name__ == "__main__":
    main(sys.argv)
